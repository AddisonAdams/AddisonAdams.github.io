---
title: "More on Matrices"
author: "Brody Erlandson"
output:
  html_document:
    code_foldIng: hide
    toc: true
    toc_float: true
    toc_depth: 2
---

\include{mathCommands}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Matrix Algebra

## Definitions and Theorems {.tabset}

### DefInition 1.1.
**Matrix**

An $m \times n$ matrix is a rectangular array of Complex numbers, with $m$ rows and $n$ columns. The number In row $i$ and column $j$ of matrix $\A$ is denoted $[\A]_{ij}$ or $a_{ij}$. If $\A$ is an $m \times n$ matrix, we often write it as

$$\A = [\mathbf{a}_1|\mathbf{a}_2|\dots|\mathbf{a}_n]$$

where $\mathbf{a}_j$ is column $j$ of $\A$, for $j = 1, 2, \dots, n$.

### DefInition 1.2. 
$\mathcal{M}_{mn}$

The set of all $m \times n$ matrices with complex entries is called the **vector space**
$\mathcal{M}_{mn}$.

### DefInition 1.3.
**Matrix Equality**

If $\A$ and $\B$ are $m \times n$ matrices, $\A = \B$ means $a_{ij} = b_{ij}$ for all $i = 1, 2, \dots, m$, and $j = 1, 2, \dots, n$.

### DefInition 1.4. 
**Matrix Addition**

If $\A$ and $\B$ are $m \times n$ matrices, the sum of $\A$ and $\B$ is the $m \times n$ matrix $\A+\B$, defined by 

$$[\A + \B]_{ij} = a_{ij} + b_{ij}$$

for all $i = 1, 2, \dots, m$, and $j = 1, 2, \dots, n$.

### DefInition 1.5.
**Matrix Scalar Multiplication**

If $\A$ is an $m \times n$ matrix and $\alpha \in \C$, the product of $\alpha$ and $\A$ is the $m \times n$ matrix $\alpha\A$, defIned by $[\alpha\A]_{ij} = \alpha[\A]_{ij}$ for all $i = 1, 2, \dots, m$, and $j = 1, 2, \dots, n$.

### DefInition 1.6.
**Zero Matrix**

The zero matrix In $\mathcal{M}_{mn}$ is the $m \times n$ matrix $\mathbf{0}_{mn}$ defIned by $[\0]_{ij} = 0$ for all $i = 1, 2, \dots, m$, and $j = 1, 2, \dots, n$

### Theorem 1.1.
**Vector Space Properties**

If $\A$, $\B$, and $\Cmat$ are $m \times n$ matrices, and $\alpha$ and $\beta$ are complex numbers, then

1. $(\A + \B) \in \mathcal{M}_{mn}$
2. $\alpha\A \in \mathcal{M}_{mn}$
3. $\A + \B = \B + \A$
4. $(\A + \B) + \Cmat = \A + (\B + \Cmat)$
5. $\A + \0 = \A,\ \forall\ \A \in \mathcal{M}_{mn}$
6. $\forall \A \in \mathcal{M}_{mn},\text{ there is a matrix }−\A\text{ such that }\A + (−\A) = \0$
7. $\alpha(\beta\A) = (\alpha\beta)\A$
8. $\alpha(A + B) = \alpha\A + \alpha\B$
9. $(\alpha + \beta)\A = \alpha\A + \beta\A$
10. $1\A = \A$

### DefInition 1.7.
**Transpose**

The transpose of a matrix $\A$ is $\A^T$, defIned by

$$[\A^T]_{ij} = [\A]_{ji}$$

for all $i = 1, 2, \dots, m$, and $j = 1, 2, \dots, n$.

### DefInition 1.8.
**Symmetric Matrices**

The matrix $\A$ is symmetric if $\A = \A^T$.

Note: only square matrices can be symmetric. You should try to prove this.
Specifically, "If A is symmetric, then A is square."

### Theorem 1.2.
**Transpose Properties**

If $\A,\B \in \mathcal{M}_{mn}$ and $\alpha \in \C$, then

1. $(\A + \B)^T = \A^T + \B^T$
2. $(\alpha\A)^T = \alpha\A^T$
3. $(\A^T)^T = \A$

### DefInition 1.9.
**Conjugate**

If $\A \in \mathcal{M}_{mn}$, the conjugate of $\A$ is $\bar{\A}$, defIned by

$[\bar{\A}]_{ij} = \overline{[\A]}_{ij}$

for all $i = 1, 2, \dots, m$, and $j = 1, 2, \dots, n$.

### Theorem 1.3.
**Conjugate Properties**

If $\A \B \in \mathcal{M}_{mn}$ and $\alpha \in C$, then

1. $\overline{\A + \B} = \bar{\A} + \bar{\B}$
2. $\overline{\alpha\A} = \bar{\alpha}\bar{\A}$
3. $\overline{(\bar{\A})} = \A$
4. $\overline{(\A^T)} = (\bar{\A})^T$

Note: sInce it doesn’t matter whether we take the conjugate or the transpose of
a matrix first, we will often simplify the notation for the ”conjugate transpose”
as follows $\overline{(\A^T)} = (\bar{\A})^T = \bar{\A}^T$

### DefInition 1.10. 
**Adjoint**

If $\A \in \mathcal{M}_{mn}$, the *adjoint* of $\A$ is $\A^*$, defIned by

$\A^* = \bar{\A}^T$

### Theorem 1.4.
**Adjoint Properties**

If $\A, \B \in \mathcal{M}_{mn}$ and $\alpha \in \C$, then

1. $(\A + \B)^* = \A^* + \B^*$
2. $(\alpha\A)^* = \alpha\A^*$
3. $(\A^*)^* = \A$

### DefInition 1.11.
**Diagonal Matrices**

A diagonal matrix is an $n \times n$ matrix with $0$’s everywhere except possibly on the main diagonal. We can write this as

$$a_{ij} = \begin{cases} 0,\ i \not= j \\ a_{ii} \in \C, i = j\end{cases}$$

## Examples

First do the following:

$$\Bigg(2\mdd{1}{7}{2}{1} + \mdd{5}{2}{3}{9}\Bigg)^T$$

<details><summary>Click here Solution</summary> 

$$\Bigg(\mdd{2}{14}{4}{2} + \mdd{5}{2}{3}{9}\Bigg)^T =  \mdd{7}{16}{7}{11}^T = \mdd{7}{7}{16}{11}$$

</details> \newline 

Which of the following are symmetric:

$$\A = \mdd{1}{0}{0}{1}, \B= \mdd{5+i}{2}{0}{14}, \Cmat = \mdd{0}{0}{0}{1}$$

Also, what is common amoungst the the matricies that are symmetric?

<details><summary>Click here Solution</summary> 

Matrix $\A$ and $\Cmat$ are symmetric, and they are also both diagonal matricies.

</details> \newline 


# Matrix Multiplication

## Definitions and Theorems {.tabset}

### DefInition 2.1. 
**Matrix-Vector Product**

If $\A \in \mathcal{M}_{mn}$ and $\v \in \C^n$, the matrix-vector product $\A\v$ is the lInear combInation

$$\A\v = \sum_{i=1}^n x_i\mathbf{a}_i$$

where $\mathbf{a}_i$ is column $i$ of $\A$.

### DefInition 2.2.
**Standard Basis Vectors**

The set of standard basis vectors In $\C^n$ is $\{\mathbf{e}_1, \mathbf{e}_2, \dots, \mathbf{e}_n\}$ where

$$[\mathbf{e}_i]_j = \begin{cases} 0, i\not=j\\ 1, i=j \end{cases}$$

for all $i = 1, 2, \dots, n$, and $j = 1, 2, \dots, n$.

### DefInition 2.3.
**Identity Matrix**

The $n \times n$ identity matrix is $\I_n$, whose columns are the standard basis vectors in $\C^n$:

$$\I_n = [\mathbf{e}_1 | \mathbf{e}_2 | \dots | \mathbf{e}_n]$$


### Theorem 2.1.
**Three Views of a System**

If $\A$ is an $m \times n$ matrix with columns $\mathbf{a}_1, \mathbf{a}_2, \dots, \mathbf{a}_n$, and if $\mathbf{b} \in \C^m$, then the matrix equation $\A\mathbf{x} = \mathbf{b}$ has the same solution set as the vector equation

$$\sum_{i=1}^n x_i\mathbf{a}_i = \mathbf{b}$$

which has the same solution set as the system of linear equations $\mathcal{LS}(\A, \mathbf{b})$.

### DefInition 2.4.
**Matrix Multiplication**

If $\A = [\bf{a}_1|\mathbf{a}_2|\dots| \bf{a}_n]$ is an $m \times n$ matrix, and $\B = [\bf{b}_1|\mathbf{b}_2|\dots| \bf{b}_p]$ is an $n \times p$ matrix, then the product of $\A$ and $\B$ is the $m \times p$ matrix $\A\B = [\A\bf{b}_1 | \A\bf{b}_2 | \dots | \A\bf{b}_p]$

### Theorem 2.2.
**Multiplicative Identity**

For all $\A \in \mathcal{M}_{mn}, \A\I_n = \A$, and $\I_m\A = \A$

*Proof*

$$\A\I_n = [\A\bf{e}_1|\dots|\A\bf{e}_n] = [\A|\dots|\A] = \A$$


### Theorem 2.3.
**Matrix Equality**

If $\A, \B \in \mathcal{M}_{mn}$, and $\A\bf{x} = \B\bf{x}$ for all $\bf{x} \in \C^n$, then $\A = \B$.

### Theorem 2.4.
**Row-Column Algorithm**

If $\A$ is an $m \times n$ matrix and $\B$ is an $n \times p$ matrix, then $\A\B$ can be computed one component at a time as

$$[\A\B]ij = \sum_{k=1}^n a_{ik}b_{kj} = a_{i1}b_{1j} + a_{i2}b_{2j} + \dots + a_{in}b_{nj}$$

### DefInition 2.5.
**Dot Product**

If $\u$ and $\v$ are vectors in $\R^n$, the dot product of $\u$ and $\v$ is

$$\u \cdot \v = \sum_{i=1}^nu_iv_i$$

### Theorem 2.5.
**Dot Product Form of Row-Column Algorithm**

If $\A$ and $\B$ are $m \times n$ and $n \times p$ matrices, with Real number entries, then the row-column algorithm for multiplyIng matrices can be written as:

$$AB = \mddd{\bf{a}_1 \cdot \bf{b}_1}{\dots}{\bf{a}_1 \cdot \bf{b}_p}{\vdots}{\ddots}{\vdots}{\bf{a}_m \cdot \bf{b}_1}{\dots}{\bf{a}_m \cdot \bf{b}_p}$$

or alternately

$$[\A\B]ij = \bf{a}_i \cdot \bf{b}_j$$

where $\bf{a}_1, \bf{a}_2, \dots, \bf{a}_m$ are the rows of $\A$, and $\bf{b}_1, \bf{b}_2, \dots, \bf{b}_p$ are the columns of $\B$.

### Theorem 2.6.
**Properties of Matrix Multiplication**

Let $\A$ be an $m \times n$ matrix, and $\B$ and $\Cmat$ have sizes for which the indicated
products are defined, and let $\alpha \in \C$.

1. $\A(\B\Cmat) = (\A\B)\Cmat$
2. $\A(\B + \Cmat) = \A\B + \A\Cmat$
3. $(\B + \Cmat)\A = \B\A + \C\A$
4. $\alpha(\A\B) = (\alpha\A)\B = \A(\alpha\B)$
5. $\0_{p\times m}\A = \0_{p\times n}$
6. $\A\0_{n\times p} = \0_{m\times p}$
7. $\I_m\A = \A = \A\I_n$
8. $(\A\B)^T = \B^T\A^T$
9. $\overline{(\A\B)} = \bar{\A}\bar{\B}$
10. $(\A\B)^* = \B^*A^*$

*Note* if $\A$ and $\B$ are matrices, $\A\B = \0$ does not imply that $\A = \0$ or $\B = \0$.

## Examples

Multiply the following:

$$\mddd{1}{0}{5}{3}{5}{6}{7}{2}{1} \vddd{1}{0}{1}$$

<details><summary>Click here Solution</summary> 

$$1 \vddd{1}{3}{7} + 0 \vddd{0}{5}{2} + 1 \vddd{5}{6}{1} = \vddd{6}{9}{8}$$

</details> \newline 

Multiply the following:

$$\mddd{0}{0}{3}{1}{2}{2}{1}{1}{1} \begin{bmatrix} 1 & 2 & 3\\ 4 & 5 & 6\\ 7 & 8 & 9\\ \end{bmatrix}$$

<details><summary>Click here Solution</summary> 

There are two ways to go about this:

$$\Bigg[ \mddd{0}{0}{3}{1}{2}{2}{1}{1}{1} \vddd{1}{4}{7} \Bigg|\mddd{0}{0}{3}{1}{2}{2}{1}{1}{1} \vddd{2}{5}{6} \Bigg|\mddd{0}{0}{3}{1}{2}{2}{1}{1}{1} \vddd{3}{6}{9}\Bigg] $$

or 

$$\left[ \begin{array}{c|c|c}
   0(1) + 0(4) + 3(7)  &  0(2) + 0(5) + 3(8) &  0(3) + 0(6) + 3(9) \\
   1(1) + 2(4) + 2(7) & 1(2) + 2(5) + 2(8) &  1(3) + 2(6) + 2(9)\\
   1(1) + 1(4) + 1(7) & 1(2) + 1(5) + 1(8) &  1(3) + 1(6) + 1(9)
  \end{array} \right] \\ = \mddd{21}{24}{27}{23}{28}{33}{12}{15}{18}$$

</details> \newline 

Finally multiply the following:

$$\mdd{1}{0}{0}{0} \mdd{0}{0}{1}{0}$$

<details><summary>Click here Solution</summary> 

$$\0_{22}$$

Note that we get the zero matrix, and niether of the matricies are the zero matrix.

</details> \newline 


# Matrices and Inner Products

## Definitions and Theorems {.tabset}

### Theorem 3.1. 
**Inner Product as Matrix Multiplication**

If $\u$ and $\v$ are in $\C^m$, then we can write the inner product of $\u$ and $\v$ as a matrix product:

$$\innerProd{\u}{\v} = \u^*\v$$

### Theorem 3.2. 
**Adjoint and Inner Product**

If $\A \in \mathcal{M}_{mn}$, $\bf{x} \in \C^n$, and $y \in \C^m$, then

$$\innerProd{\A\bf{x}}{\bf{y}} = \innerProd{\bf{x}}{\A^*\bf{y}}$$

*Proof*

$$\innerProd{\A\bf{x}}{\bf{y}} \\ = (\A\bf{x})^*\bf{y} \\= \bf{x}^*\A^*\bf{y} \\= \bf{x}^*(\A^*\bf{y}) \\= \innerProd{\bf{x}}{\A^*\bf{y}}$$

### Definition 3.1. 
**Hermitian Matrices**

A square matrix $\A$ is Hermitian if $\A = \A^*$. Hermitian matrices are also sometimes called self-adjoint.

### Theorem 3.3.
**Hermitian Matrices and Inner Product**

If $\A$ is $n \times n$, and $\bf{x}, \bf{y} \in \C^n$, then $\A$ is Hermitian iff $\innerProd{\A\bf{x}}{\bf{y}} = \innerProd{\bf{x}}{\A\bf{y}}$ for all $\bf{x}, \bf{y} \in \C^n$.

*Proof*

First, assume  $\A$ is $n \times n$, and $\bf{x}, \bf{y} \in \C^n$, and $\A$ is Hermitian, then

$$\innerProd{\A\bf{x}}{\bf{y}} = \innerProd{\bf{x}}{\A^*\bf{y}} = \innerProd{\bf{x}}{\A\bf{y}}$$

Now,  assume  $\A$ is $n \times n$, and $\bf{x}, \bf{y} \in \C^n$, and $\innerProd{\A\bf{x}}{\bf{y}} = \innerProd{\bf{x}}{\A\bf{y}}$, then

$$\innerProd{\A\bf{x} - \A^*\bf{x}}{\A\bf{x} - \A^*\bf{x}} = \innerProd{\A\bf{x} - \A^*\bf{x}}{\A\bf{x}} - \innerProd{\A\bf{x} - \A^*\bf{x}}{\A^*\bf{x}} 
  \\= \innerProd{\A\bf{x} - \A^*\bf{x}}{\A\bf{x}} - \innerProd{\A(\A\bf{x} - \A^*\bf{x})}{\bf{x}}
  \\= \innerProd{\A\bf{x} - \A^*\bf{x}}{\A\bf{x}} - \innerProd{\A\bf{x} - \A^*\bf{x}}{\A\bf{x}}
  \\= 0$$
  
Now, $\innerProd{\u}{\u}=0$ iff $\u = 0$. Thus, $\A\bf{x} - \A^*\bf{x} = 0 \Rightarrow \A\bf{x} = \A^*\bf{x} \Rightarrow \A = \A^*$
